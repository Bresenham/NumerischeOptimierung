\documentclass[a4paper, 12pt]{report}
\usepackage{graphicx}
\usepackage[utf8]{inputenc}
\usepackage[ngerman]{babel}
\usepackage{geometry}
\usepackage{csquotes}
\usepackage[toc,page]{appendix}
\usepackage{titlesec}
\usepackage{listings}
\usepackage{float}
\usepackage[hang,flushmargin]{footmisc} 
\usepackage{makecell}
\usepackage{amsmath}% http://ctan.org/pkg/amsmath
\usepackage[utf8]{inputenc}
\usepackage[default]{cantarell} %% Use option "defaultsans" to use cantarell as sans serif only
\usepackage[T1]{fontenc}
\usepackage{hyperref}
\usepackage{helvet}
\usepackage[eulergreek]{sansmath}
\usepackage{amsfonts}
\usepackage{movie15}
\usepackage{url}
\usepackage{lscape}
\usepackage{changepage}

\usepackage{tikz}
\usetikzlibrary{calc,positioning,shapes,decorations.pathreplacing}
\usetikzlibrary{fit,fadings,shadows,patterns,math}
\usetikzlibrary{shapes.arrows,shapes.geometric}
\usetikzlibrary{arrows,arrows.meta,decorations.markings}
\usetikzlibrary{decorations.pathmorphing}

\usepackage{pgfplots}

\graphicspath{ {./images/} }
\geometry{margin=1.25in}

\newcommand*{\shifttext}[2]{%
  \settowidth{\@tempdima}{#2}%
  \makebox[\@tempdima]{\hspace*{#1}#2}%
}
\newcommand{\fakesection}[1]{%
  \par\refstepcounter{section}% Increase section counter
  \sectionmark{#1}% Add section mark (header)
  \addcontentsline{toc}{section}{\protect\numberline{\thesection}#1}% Add section to ToC
  % Add more content here, if needed.
}
\titleformat{\chapter}[display]
  {\normalfont\bfseries}{}{0pt}{\Large}
\titleformat*{\section}{\large\bfseries}

\renewcommand{\footnoterule}{%
  \kern -3pt
  \hrule width \textwidth height 1pt
  \kern 2pt
}

\newcommand\blfootnote[1]{%
  \begingroup
  \renewcommand\thefootnote{}\footnote{#1}%
  \addtocounter{footnote}{-1}%
  \endgroup
}

\begin{document}

\begin{center}
    \vspace*{2em}
    \normalsize 2. Projekt\\
    \vspace*{1em}
    \normalsize \textbf{\textit{Quasi-Newton-Verfahren \& Gauß-Newton-Verfahren}}\\
    \vspace*{4em}
    \normalsize im Fach\\
    \vspace*{1em}
    \large Numerische Optimierung\\
    \vspace*{30em}
    \normalsize Juni 2020\\
    \vspace*{1em}
    \normalsize Maximilian Gaul
\end{center}

\thispagestyle{empty}

\newpage

\subsubsection{Aufgabe 1}
Siehe Programmcode in \lstinline[basicstyle=\ttfamily\color{black}]|Project2.m|.

\subsubsection{Aufgabe 2}
Für $A^0$ wählt man im BFGS-Verfahren üblicherweise die Einheitsmatrix, d.h. für den Induktionsanfang gilt:

$$A^0 = I$$

Wenn man das nun in die Formel für die zwei Rang-1-Modifikationen und in die BFGS-Update-Formel einsetzt erhält man den Ansatz
(für $B = A^{-1} = I$):

$$\left( I + \frac{ss^T - ys^T + ss^T - sy^T}{y^Ts} - \frac{s^Tyss^T - y^Tyss^T}{(y^T)s^2}\right)\cdot\left(I - \frac{ss^T}{s^Ts} + \frac{yy^T}{y^Ts} \right)$$

Der Übersicht halber teile ich die einzelnen Produkte auf und füge sie nach dem Kürzen am Ende wieder zusammen.
Es ist zu beachten, dass $y^Ts = s^Ty$. Skalare Werte werden gekürzt.

$$I\cdot I = I$$

$$I \cdot \left(-\frac{ss^T}{s^Ts}\right) = -\frac{ss^T}{s^Ts}$$

$$I\cdot \left(\frac{yy^T}{y^Ts}\right) = \frac{yy^T}{y^Ts}$$

$$\left(\frac{ss^T - ys^T + ss^T - sy^T}{y^Ts}\right) \cdot I = \frac{ss^T}{y^Ts} - \frac{ys^T}{y^Ts} + \frac{ss^T}{y^Ts} - \frac{sy^T}{y^Ts}$$

$$\left(\frac{ss^T - ys^T + ss^T - sy^T}{y^Ts}\right)\cdot\left( - \frac{ss^T}{s^Ts} \right) = -\frac{ss^Tss^T - ys^Tss^T + ss^Tss^T - sy^Tss^T}{y^Tss^Ts}$$

$$= -\frac{s\textcolor{red}{s^Ts}s^T}{y^Ts\textcolor{red}{s^Ts}} + \frac{y\textcolor{red}{s^Ts}s^T}{y^Ts\textcolor{red}{s^Ts}} - \frac{s\textcolor{red}{s^Ts}s^T}{y^Ts\textcolor{red}{s^Ts}} + \frac{s\textcolor{red}{y^Ts}s^T}{\textcolor{red}{y^Ts}s^Ts} = -\frac{ss^T}{y^Ts} + \frac{ys^T}{y^Ts} - \frac{ss^T}{y^Ts} + \frac{ss^T}{s^Ts}$$

$$\left(\frac{ss^T - ys^T + ss^T - sy^T}{y^Ts}\right)\cdot \left( \frac{yy^T}{y^Ts} \right) = \frac{ss^Ty - ys^Tyy^T + ss^Tyy^T - sy^Tyy^T}{(y^Ts)^2}$$

$$= \frac{s\textcolor{red}{s^Ty}y^T}{(\textcolor{red}{y^Ts})^2} - \frac{y\textcolor{red}{s^Ty}y^T}{(\textcolor{red}{y^Ts})^2} + \frac{s\textcolor{red}{s^Ty}y^T}{(\textcolor{red}{y^Ts})^2}  - \frac{sy^Tyy^T}{(y^Ts)^2} = \frac{sy^T}{y^Ts} - \frac{yy^T}{y^Ts} + \frac{sy^T}{y^Ts} - \frac{sy^Tyy^T}{(y^Ts)^2} $$

$$ \left(-\frac{s^Tyss^T - y^Tyss^T}{(y^Ts)^2} \right)\cdot I = -\frac{\textcolor{red}{s^Ty}ss^T}{(\textcolor{red}{y^Ts})^2} + \frac{y^Tyss^T}{(y^Ts)^2} = -\frac{ss^T}{y^Ts} + \frac{y^Tyss^T}{(y^Ts)^2} $$

$$ \left(-\frac{s^Tyss^T - y^Tyss^T}{(y^Ts)^2} \right)\cdot \left( - \frac{ss^T}{s^Ts} \right) = \frac{s^Tyss^Tss^T - y^Tyss^Tss^T}{(y^Ts)^2s^Ts}$$

$$= \frac{\textcolor{red}{s^Ty}s\textcolor{blue}{s^Ts}s^T}{(\textcolor{red}{y^Ts})^2\textcolor{blue}{s^Ts}} - \frac{y^Tys\textcolor{blue}{s^Ts}s^T}{(y^Ts)^2\textcolor{blue}{s^Ts}} = \frac{ss^T}{y^Ts} - \frac{y^Tyss^T}{(y^Ts)^2}$$

$$ \left(-\frac{s^Tyss^T - y^Tyss^T}{(y^Ts)^2} \right)\cdot \left( \frac{yy^T}{y^Ts} \right) = -\frac{s^Tyss^Tyy^T + y^Tyss^Tyy^T}{(y^Ts)^3} $$

$$= -\frac{\textcolor{red}{s^Ty}s\textcolor{red}{s^Ty}y^T}{(\textcolor{red}{y^Ts})^3} + \frac{y^Tys\textcolor{red}{s^Ty}y^T}{(\textcolor{red}{y^Ts})^3} = -\frac{sy^T}{y^Ts} + \frac{y^Tysy^T}{(y^Ts)^2}$$

Zusammenfassen:

$$ I \textcolor{red}{-\frac{ss^T}{s^Ts}} \textcolor{blue}{+\frac{yy^T}{y^Ts}} \textcolor{green}{+\frac{ss^T}{y^Ts}} \textcolor{orange}{-\frac{ys^T}{y^Ts}} \textcolor{violet}{+\frac{ss^T}{y^Ts}} \textcolor{magenta}{-\frac{sy^T}{y^Ts}} \textcolor{green}{-\frac{ss^T}{y^Ts}} \textcolor{orange}{+\frac{ys^T}{y^Ts}} \textcolor{violet}{-\frac{ss^T}{y^Ts}} \textcolor{red}{+\frac{ss^T}{s^Ts}} \textcolor{magenta}{+\frac{sy^T}{y^Ts}} \textcolor{blue}{-\frac{yy^T}{y^Ts}} \textcolor{cyan}{+\frac{sy^T}{y^Ts}} $$
$$ \textcolor{purple}{-\frac{sy^Tyy^T}{(y^Ts)^2}} \textcolor{brown}{-\frac{ss^T}{y^Ts}} + \frac{y^Tyss^T}{(y^Ts)^2} \textcolor{brown}{+\frac{ss^T}{y^Ts}} - \frac{y^Tyss^T}{(y^Ts)^2} \textcolor{cyan}{-\frac{sy^T}{y^Ts}} \textcolor{purple}{+\frac{y^Tysy^T}{(y^Ts)^2}} = I $$

Im Induktionsschritt geht man von $k = 0$ auf allgemeines $k$, dann erhält man folgenden Ansatz (für $B = A^{-1}$, $k$ wurde zur besseren Übersichtlichkeit weggelassen):

$$\left(A^{-1} + \frac{(s - A^{-1}y)s^T + s(s - A^{-1}y)^T}{y^Ts} - \frac{(s - A^{-1}y)^Tyss^T}{(y^Ts)^2} \right) \cdot \left(A - \frac{As(As)^T}{s^TAs} + \frac{yy^T}{y^Ts} \right) $$

Die einzeln Produkte werden wieder aufgeteilt:

$$\left(A^{-1} \right)\cdot \left(A \right) = I$$

$$\left(A^{-1} \right)\cdot \left(- \frac{As(As)^T}{s^TAs} \right) = - \frac{s(As)^T}{s^TAs} = -\frac{ss^TA}{s^TAs}$$

$$\left(A^{-1} \right)\cdot \left( \frac{yy^T}{y^Ts} \right) = \frac{A^{-1}yy^T}{y^Ts}$$

$$\left(\frac{(s - A^{-1}y)s^T + s(s - A^{-1}y)^T}{y^Ts} \right)\cdot \left(A \right) = \frac{ss^TA - A^{-1}ys^TA + ss^TA - sy^TA^{-1}A}{y^Ts} $$

$$= \frac{ss^TA}{y^Ts} - \frac{A^{-1}ys^TA}{y^Ts} + \frac{ss^TA}{y^Ts} - \frac{sy^T}{y^Ts}$$

\begin{adjustwidth}{-65pt}{0pt}
  $$\left(\frac{(s - A^{-1}y)s^T + s(s - A^{-1}y)^T}{y^Ts} \right)\cdot \left( - \frac{As(As)^T}{s^TAs} \right) = -\frac{ss^TAss^TA - A^{-1}ys^TAss^TA + s(s^T - y^TA^{-1})Ass^TA}{y^Tss^TAs} $$
\end{adjustwidth}

$$= -\frac{s\textcolor{red}{s^TAs}s^TA}{y^Ts\textcolor{red}{s^TAs}} + \frac{A^{-1}y\textcolor{red}{s^TAs}s^TA}{y^Ts\textcolor{red}{s^TAs}} - \frac{s\textcolor{red}{s^TAs}s^TA}{y^Ts\textcolor{red}{s^TAs}} + \frac{s\textcolor{red}{y^Ts}s^TA}{\textcolor{red}{y^Ts}s^TAs}$$

$$=  -\frac{ss^TA}{y^Ts}  + \frac{A^{-1}ys^TA}{y^Ts} - \frac{ss^TA}{y^Ts} + \frac{ss^TA}{s^TAs}$$

\begin{adjustwidth}{-25pt}{0pt}
  $$\left(\frac{(s - A^{-1}y)s^T + s(s - A^{-1}y)^T}{y^Ts} \right)\cdot \left( \frac{yy^T}{y^Ts} \right) = \frac{ss^Tyy^T - A^{-1}ys^Tyy^T + ss^Tyy^T - sy^TA^{-1}yy^T}{(y^Ts)^2}$$
\end{adjustwidth}

$$= \frac{s\textcolor{red}{s^Ty}y^T}{(\textcolor{red}{y^Ts})^2} - \frac{A^{-1}y\textcolor{red}{s^Ty}y^T}{(\textcolor{red}{y^Ts})^2} + \frac{s\textcolor{red}{s^Ty}y^T}{(\textcolor{red}{y^Ts})^2} - \frac{sy^TA^{-1}yy^T}{(y^Ts)^2}$$

$$= \frac{sy^T}{y^Ts} - \frac{A^{-1}yy^T}{y^Ts} + \frac{sy^T}{y^Ts} - \frac{sy^TA^{-1}yy^T}{(y^Ts)^2}$$

$$\left( - \frac{(s - A^{-1}y)^Tyss^T}{(y^Ts)^2} \right)\cdot \left(A \right) = -\frac{s^Tyss^TA - y^TA^{-1}yss^TA}{(y^Ts)^2}$$

$$= -\frac{\textcolor{red}{s^Ty}ss^TA}{(\textcolor{red}{y^Ts})^2} + \frac{y^TA^{-1}yss^TA}{(y^Ts)^2} = -\frac{ss^TA}{y^Ts} + \frac{y^TA^{-1}yss^TA}{(y^Ts)^2}$$

$$\left(  - \frac{(s - A^{-1}y)^Tyss^T}{(y^Ts)^2} \right)\cdot \left( - \frac{As(As)^T}{s^TAs} \right) = \frac{s^Tyss^TAss^TA - y^TA^{-1}yss^TAss^TA}{(y^Ts)^2s^TAs}$$

$$= \frac{\textcolor{red}{s^Ty}s\textcolor{blue}{s^TAs}s^TA}{(\textcolor{red}{y^Ts})^2\textcolor{blue}{s^TAs}} - \frac{y^TA^{-1}ys\textcolor{red}{s^TAs}s^TA}{(y^Ts)^2\textcolor{red}{s^TAs}} = \frac{ss^TA}{y^Ts} - \frac{y^TA^{-1}yss^TA}{(y^Ts)^2}$$

$$\left(  - \frac{(s - A^{-1}y)^Tyss^T}{(y^Ts)^2} \right)\cdot \left( \frac{yy^T}{y^Ts} \right) = -\frac{s^Tyss^Tyy^T - y^TA^{-1}yss^Tyy^T}{(y^Ts)^3} $$

$$= -\frac{\textcolor{red}{s^Ty}s\textcolor{red}{s^Ty}y^T}{(\textcolor{red}{y^Ts})^3} + \frac{y^TA^{-1}ys\textcolor{red}{s^Ty}y^T}{(\textcolor{red}{y^Ts})^3} = -\frac{sy^T}{y^Ts} + \frac{y^TA^{-1}ysy^T}{(y^Ts)^2}$$

Zusammenfassen

$$ I \textcolor{red}{-\frac{ss^TA}{s^TAs}} \textcolor{blue}{+\frac{A^{-1}yy^T}{y^Ts}} \textcolor{green}{+\frac{ss^TA}{y^Ts}} \textcolor{purple}{-\frac{A^{-1}ys^TA}{y^Ts}} \textcolor{cyan}{+\frac{ss^TA}{y^Ts}} \textcolor{orange}{-\frac{sy^T}{y^Ts}} \textcolor{green}{-\frac{ss^TA}{y^Ts}}  \textcolor{purple}{+\frac{A^{-1}ys^TA}{y^Ts}} \textcolor{cyan}{-\frac{ss^TA}{y^Ts}} $$

$$ \textcolor{red}{+\frac{ss^TA}{s^TAs}} \textcolor{orange}{+\frac{sy^T}{y^Ts}} \textcolor{blue}{-\frac{A^{-1}yy^T}{y^Ts}} \textcolor{brown}{+\frac{sy^T}{y^Ts}} \textcolor{magenta}{-\frac{sy^TA^{-1}yy^T}{(y^Ts)^2}} \textcolor{violet}{-\frac{ss^TA}{y^Ts}} + \frac{y^TA^{-1}yss^TA}{(y^Ts)^2} $$

$$ \textcolor{violet}{+\frac{ss^TA}{y^Ts}} - \frac{y^TA^{-1}yss^TA}{(y^Ts)^2} \textcolor{brown}{-\frac{sy^T}{y^Ts}} \textcolor{magenta}{+\frac{y^TA^{-1}ysy^T}{(y^Ts)^2}} = I $$ 

Da $y^TA^{-1}y$ ein Skalar ist, kann es beliebig verschoben werden, d.h. $sy^TA^{-1}yy^T = y^TA^{-1}ysy^T$.

Für $k + 1$ ändert sich an der oben gezeigten Rechnung nichts. Jeder Vektor bzw. jede Matrix erhält dann einfach nur den Index $k + 1$.

\subsubsection{Aufgabe 3}
Wenn die Suchrichtung des BFGS Verfahrens:

$$d = -B\cdot \nabla f(x) $$

keine Abstiegsrichtung ist, d.h. die Bedingung:

$$\nabla f(x)^T \cdot d < 0 $$

nicht erfüllt ist, muss das Verfahren 'resettet' werden. In diesem Fall bietet es sich an, die Suchrichtung auf den
negativen Gradienten zu setzen:

$$d = -\nabla f(x)$$

Da nun die Abstiegsrichtung nicht mehr zur approximierten Inversen der Hesse-Matrix $B$ passt, muss diese ebenfalls für
den nächsten Schritt neu bestimmt werden (bzw. das nächste Update erfolgt dann mit dieser Matrix).\par
Hierzu bieten sich verschiedene Möglichkeiten an:

\begin{itemize}
  \item Wie beim Start des BFGS-Verfahrens $B = I$ setzen
  \begin{itemize}
    \item Hierbei geht jeglicher berechnete Fortschritt verloren, es handelt sich um einen recht naiven Ansatz
  \end{itemize}
  \item Die Hesse-Matrix einmalig aus Differenzenquotienten des Gradienten bestimmen und anschließend invertieren
  \begin{itemize}
    \item Hoher Rechenaufwand von $\mathcal{O}(n^2)$ für die Hesse-Matrix und nochmal $\mathcal{O}(n^3)$ für das Invertieren
    \item Problem wenn die Hesse-Matrix nicht invertierbar ist bzw. aufgrund von Auslöschung oder anderen numerischen Fehlern
    die Inverse schlecht konditioniert ist
    \item Bisher berechneter Fortschritt geht ebenfalls verloren aber die Approximation der Hesse-Matrix ist sehr genau
  \end{itemize}
  \item Man könnte, wie in den Vorlesungsfolien beschrieben,  $\frac{y^Ts}{y^Ty}\cdot I_n$ als positiv-definitve Matrix verwenden
  \begin{itemize}
    \item Der Fortschritt geht zwar ähnlich wie bei $B = I$ weitestgehend verloren, allerdings überträgt man noch Informationen
    von $y$ und $s$ auf den nächsten Schritt, erscheint also sinnvoller als die erste Variante
  \end{itemize}
\end{itemize}

Um herauszufinden, welche dieser Methoden am besten geeignet ist (d.h. die richtig Lösung in der kürzesten Zeit findet),
wird die Laufzeit des inversen BFGS-Verfahrens bestimmt. Startwerte:

\begin{itemize}
  \item N-dim. Rosenbrock-Funktion: $\begin{bmatrix}-1\\\vdots\\-1\end{bmatrix}$
  \item Himmelblau-Funktion: $\begin{bmatrix}0\\-1\end{bmatrix}$
  \item Bazaraa-Shetty: $\begin{bmatrix}0\\-1\end{bmatrix}$
\end{itemize}

\begin{figure}[H]
  \centering
  \pgfplotstableread{
    0 0.2240  0.0030  0.0051
  }\dataseth
  \pgfplotstableread{
    0 0.2089  0.0023  0.0043
  }\datasetf
  \pgfplotstableread{
    0 0.0       16.337017     3.398372
  }\datasetg
  \begin{minipage}{.3\textwidth}
    \begin{tikzpicture}
        \pgfplotsset{
          tick label style = {font=\sansmath\sffamily},
          every axis label = {font=\sansmath\sffamily},
          legend style = {font=\sansmath\sffamily},
          label style = {font=\sansmath\sffamily}
        }
        \begin{axis}[
            width=4cm,
            height=6.5cm,
            ybar,
            ymin=0,
            ymax=0.25,
            ylabel={Rechenzeit in s},
            ylabel style={xshift=-3ex},
            ytick distance=0.1,
            % ytick=\empty,
            % extra y ticks={0,0.05,0.10,0.15,0.2,0.25},
            % extra y tick labels={{0},{0.05},{0.10},{0.15},{0.2},{0.25}},
            xtick=data,
            xticklabels={
                $B = I$
            },
            yticklabel style={xshift=0ex},
            xticklabel style={yshift=-16ex},
            major x tick style={
                % (this is a better way than assigning `opacity=0')
                /pgfplots/major tick length=0pt,
            },
            minor x tick num=1,
            minor tick length=2ex,
            % ---------------------------------------------------------------------
            % (adapted solution from <https://tex.stackexchange.com/a/141006/95441>)
            % we want to provide absolute `at' values ...
            scatter/position=absolute,
            node near coords style={
                % ... to provide axis coordinates at `ymin' for the nodes
                at={(axis cs:\pgfkeysvalueof{/data point/x},\pgfkeysvalueof{/pgfplots/ymin})},
                % then also the `anchor' has to be adapted ...
                anchor=east,
                % ... because we rotate the labels which would overlap otherwise
                rotate=90,
            },
            % ---------------------------------------------------------------------
            % (created a cycle list to shorten the below `\addplot' entries)
            cycle list={
                {draw=black,fill=black!20},
                {draw=black,fill=black!40},
                {draw=black,fill=black!60},
            },
            % (moved common option here)
            table/x index=0,
        ]
            \addplot+ [nodes near coords=200-dim. Rosen.] table [y index=1] \dataseth;
            \addplot+ [nodes near coords=Himmelblau] table [y index=2] \dataseth;
            \addplot+ [nodes near coords=Bazaraa-Shetty] table [y index=3] \dataseth;
        \end{axis}
        \node[black, rotate=90, align=left] (impl) at (1.2125,1.08) {0.0030};
        \draw[-{Latex}, thick, black] (impl.west) -- ([yshift=-0.2cm]impl.west);

        \node[black, rotate=90, align=left] (impl2) at (1.6255,1.124) {0.0051};
        \draw[-{Latex}, thick, black] (impl2.west) -- ([yshift=-0.2cm]impl2.west);
    \end{tikzpicture}
  \end{minipage}
  \begin{minipage}{.3\textwidth}
    \begin{tikzpicture}
      \pgfplotsset{
        tick label style = {font=\sansmath\sffamily},
        every axis label = {font=\sansmath\sffamily},
        legend style = {font=\sansmath\sffamily},
        label style = {font=\sansmath\sffamily}
      }
        \begin{axis}[
            width=4cm,
            height=6.5cm,
            ybar,
            ymin=0,
            ymax=0.25,
            % ytick=\empty,
            % extra y ticks={0,0.05,0.10,0.15,0.2,0.25},
            % extra y tick labels={{0},{0.05},{0.10},{0.15},{0.2},{0.25}},
            xtick=data,
            xticklabels={
                $B = \frac{y^Ts}{y^Ty}\cdot I$
            },
            xticklabel style={yshift=-16ex},
            major x tick style={
                % (this is a better way than assigning `opacity=0')
                /pgfplots/major tick length=0pt,
            },
            minor x tick num=1,
            minor tick length=2ex,
            % ---------------------------------------------------------------------
            % (adapted solution from <https://tex.stackexchange.com/a/141006/95441>)
            % we want to provide absolute `at' values ...
            scatter/position=absolute,
            node near coords style={
                % ... to provide axis coordinates at `ymin' for the nodes
                at={(axis cs:\pgfkeysvalueof{/data point/x},\pgfkeysvalueof{/pgfplots/ymin})},
                % then also the `anchor' has to be adapted ...
                anchor=east,
                % ... because we rotate the labels which would overlap otherwise
                rotate=90,
            },
            % ---------------------------------------------------------------------
            % (created a cycle list to shorten the below `\addplot' entries)
            cycle list={
              {draw=black,fill=black!20},
              {draw=black,fill=black!40},
              {draw=black,fill=black!60},
            },
            % (moved common option here)
            table/x index=0,
        ]
        \addplot+ [nodes near coords=200-dim. Rosen.] table [y index=1] \datasetf;
        \addplot+ [nodes near coords=Himmelblau] table [y index=2] \datasetf;
        \addplot+ [nodes near coords=Bazaraa-Shetty] table [y index=3] \datasetf;
        \end{axis}
        \node[black, rotate=90, align=left] (impl) at (1.2125,1.055) {0.0023};
        \draw[-{Latex}, thick, black] (impl.west) -- ([yshift=-0.2cm]impl.west);

        \node[black, rotate=90, align=left] (impl2) at (1.6255,1.1) {0.0043};
        \draw[-{Latex}, thick, black] (impl2.west) -- ([yshift=-0.2cm]impl2.west);
    \end{tikzpicture}
  \end{minipage}
  \caption{Vergleich der Rechenzeit für eine Genauigkeit von $10^{-8}$ gemittelt über 100 Durchläufe (Intel Core i3-7100U, 8GB RAM, Windows 10 64-Bit)}
\end{figure}

Alle drei Funktionen profitieren von $B = \frac{y^Ts}{y^Ty}\cdot I$, daher habe ich diesen Weg in meiner Implementierung gewählt.

\subsubsection{Aufgabe 4}

Auswertungen der Himmelblau-Funktion

$$f(x_1, x_2) = (x_1^2 + x_2 - 11)^2 + (x_1 + x_2^2 - 7)^2$$

Mit Gradient:

\def\arraystretch{1.25}
$$\nabla f(x_1, x_2) = \begin{bmatrix} 2\cdot(x_1^2 + x_2 - 11)\cdot 2x_1 + 2\cdot(x_1 + x_2^2 - 7) \\ 
                2\cdot (x_1^2 + x_2 - 11) + 2\cdot(x_1 + x_2^2 - 7)\cdot 2x_2 \end{bmatrix}$$

\begin{figure}[H]
  \centering
  \def\arraystretch{1.25}
  \begin{tabular}{l|c|r}
    \hline
    \textbf{Schritt} & \textbf{x} & \textbf{$f(x)$}\\
    \hline
    1 & $[0.00, -1.00]^T$ & 180\\
    2 & $[4.50, -1.00]^T$ & 70.31\\
    3 & $[2.54, -1.86]^T$ & 41.79\\
    4 & $[2.68, -2.26]^T$ & 37.84\\
    5 & $[4.16, -1.94]^T$ & 20.24\\
    6 & $[3.34, -1.83]^T$ & 02.93\\
    7 & $[3.53, -1.84]^T$ & 00.14\\
    8 & $[3.59, -1.85]^T$ & 00.00\\
    $\vdots$ & $\vdots$ & $\vdots$\\
    13 & $[3.58, -1.85]^T$ & $6.37 \cdot 10^{-20}$\\
    \hline
  \end{tabular}
  \caption{Verlauf von \lstinline[basicstyle=\ttfamily\color{black}]|InverseBFGS| für $f$ bei einer Genauigkeit von $10^{-8}$. Man erkennt
  gut die superlineare Konvergenz.}
\end{figure}

\begin{figure}[H]
  \centering
  \def\arraystretch{1.25}
  \begin{tabular}{l|c|r}
    \hline
    \textbf{Schritt} & \textbf{x} & \textbf{$f(x)$}\\
    \hline
    1 & $[0.00, -1.00]^T$ & 180\\
    2 & keine Info & 06.38\\
    3 & keine Info & 05.91\\
    4 & keine Info & 00.26\\
    5 & keine Info & 0.00\\
    $\vdots$ & $\vdots$ & $\vdots$\\
    9 & $[3.58, -1.85]^T$ & $7.05\cdot 10^{-13}$\\
    \hline
  \end{tabular}
  \caption{Verlauf von \lstinline[basicstyle=\ttfamily\color{black}]|fminunc| für $f$ bei einer Genauigkeit von $10^{-8}$ mit Einstellungen
  \lstinline[basicstyle=\ttfamily\color{black}]|HessUpdate = 'bfgs'| und \lstinline[basicstyle=\ttfamily\color{black}]|Display = 'iter-detailed'|.}
\end{figure}

Die Rosenbrock-Funktion ist in \lstinline[basicstyle=\ttfamily\color{black}]|Projekt2.m| als 
\lstinline[basicstyle=\ttfamily\color{black}]|f_rosen_mult| definiert. Beispielhaft für $N = 3$

  $$g(x_1, x_2, x_3) = \sum_{i=1}^2 (1 - x_i)^2 + 100\cdot(x_{i+1} - x_i^2)^2$$
  $$=$$
  $$(1 - x_1)^2 + 100\cdot (x_2 - x_1^2)^2 + (1 - x_2)^2 + 100\cdot(x_3 - x_2^2)^2$$

habe ich den Gradienten bestimmt:

\def\arraystretch{1.25}
  $$\nabla g_3 = \begin{bmatrix}-2\cdot(1 - x_1) + 200\cdot(x_2 - x_1^2)\cdot(-2x_1)\\
    200\cdot(x_2 - x_1^2) - 2\cdot(1 - x_2) + 200\cdot(x_3 - x_2^2)\cdot(-2x_2)\\
    200\cdot(x_3 - x_2^2)\end{bmatrix}$$

Man erkennt eine Regel: Der Gradient besteht aus drei Teilen. Der erste Eintrag im Gradienten ist:

$$-2\cdot(1 - x_1) + 200\cdot(x_2 - x_1^2)\cdot(-2x_1)$$

Alle weiteren Einträge (bis auf den letzten an Position $N-1$) sind:

$$200\cdot(x_i - x_{i-1}^2) - 2\cdot(1 - x_i) + 200\cdot(x_{i+1} - x_i^2)\cdot(-2x_i)$$

Der letzte Eintrag ist:

$$200\cdot(x_N - x_{N-1}^2)$$

Die Ableitung ist in \lstinline[basicstyle=\ttfamily\color{black}]|Projekt2.m| in der Funktion
\lstinline[basicstyle=\ttfamily\color{black}]|f_rosen_mult_deriv_func| definiert.

\begin{figure}[H]
  \centering
  \begin{tikzpicture}
    \pgfplotsset{
      tick label style = {font=\sansmath\sffamily},
      every axis label = {font=\sansmath\sffamily},
      legend style = {font=\sansmath\sffamily},
      label style = {font=\sansmath\sffamily}
    }
    \pgfplotstableread[col sep=comma]{bfgs_ndim_rosen_measurement.csv}\datatable
    \begin{axis}[
        ybar,
        bar width=0.375pt,
        ymin=0,
        ymax=3.2,
        ytick distance=0.5,
        ylabel={Rechenzeit in s},
        xmin=0,
        xmax=450,
        xtick distance=50,
        xlabel={Dimension},
        height=4.5cm,
        width=0.95\textwidth,
        tick align=inside
      ]
      \addplot[fill=black!40, draw=black] table[x index = {0}, y index = {1}] {\datatable};
    \end{axis}
  \end{tikzpicture}
\caption{Rechenzeit der N-dimensionalen Rosenbrock-Funktion mit Startwert $[-1, \ldots, -1]^T$ für
  eine Genauigkeit von $10^{-8}$ gemittelt über 100 Durchläufe von \lstinline[basicstyle=\ttfamily\color{black}]|InverseBFGS|
  (Intel Core i3-7100U, 8GB RAM, Windows 10 64-Bit)}
\end{figure}

\begin{figure}[H]
  \centering
  \begin{tikzpicture}
    \pgfplotsset{
      tick label style = {font=\sansmath\sffamily},
      every axis label = {font=\sansmath\sffamily},
      legend style = {font=\sansmath\sffamily},
      label style = {font=\sansmath\sffamily}
    }
    \pgfplotstableread[col sep=comma]{fminunc_ndim_rosen_measurement.csv}\datatable
    \begin{axis}[
        ybar,
        bar width=0.375pt,
        ymin=0,
        ymax=3.2,
        ytick distance=0.5,
        ylabel={Rechenzeit in s},
        xmin=0,
        xmax=450,
        xtick distance=50,
        xlabel={Dimension},
        height=4.5cm,
        width=0.95\textwidth,
        tick align=inside
      ]
      \addplot[fill=black!40, draw=black] table[x index = {0}, y index = {1}] {\datatable};
    \end{axis}
  \end{tikzpicture}
\caption{Rechenzeit der N-dimensionalen Rosenbrock-Funktion mit Startwert $[-1, \ldots, -1]^T$ für
  eine Genauigkeit von $10^{-8}$ gemittelt über 100 Durchläufe von \lstinline[basicstyle=\ttfamily\color{black}]|fminunc| mit
  \lstinline[basicstyle=\ttfamily\color{black}]|HessUpdate = 'bfgs'| (Intel Core i3-7100U, 8GB RAM, Windows 10 64-Bit)}
\end{figure}

Man erkennt, das mit höheren Dimensionen die Rechenzeit für beide Verfahren drastisch zunimmt und
\lstinline[basicstyle=\ttfamily\color{black}]|fminunc| deutlich früher 3s pro Durchlauf benötigt.\par

\begin{figure}[H]
  \centering
  \def\arraystretch{1.25}
  \begin{adjustwidth}{-25.5pt}{0pt}
  \begin{tabular}{l|c|c|c|r}
    \hline
    \textbf{Verfahren} & \textbf{Dimensionen} & \textbf{Dauer} & \textbf{Genauigkeit} & \textbf{Anmerkung}\\
    \hline
    \lstinline[basicstyle=\ttfamily\color{black}]|InverseBFGS| & 750 & 14.05s & $10^{-8}$ & \makecell[r]{Zielfunktionswert: 3.98,\\die ersten 8 Werte bei 0.9967}\\
    \lstinline[basicstyle=\ttfamily\color{black}]|InverseBFGS| & 850 & 22.07s & $10^{-8}$ & \makecell[r]{Zielfunktionswert: $1.4 \cdot 10^{-20}$,\\keine Werte $\neq$ 1}\\
    \lstinline[basicstyle=\ttfamily\color{black}]|InverseBFGS| & 925 & 24.66s & $10^{-8}$ & \makecell[r]{Zielfunktionswert: $5.8 \cdot 10^{-21}$,\\keine Werte $\neq$ 1}\\
    \lstinline[basicstyle=\ttfamily\color{black}]|fminunc| & 750 & 127.95s & $10^{-8}$ & \makecell[r]{Zielfunktionswert: $1.8\cdot 10^{-10}$,\\keine Werte $\neq$ 1}\\
    \lstinline[basicstyle=\ttfamily\color{black}]|fminunc| & 850 & 152.15s & $10^{-8}$ & \makecell[r]{Zielfunktionswert: $1.7\cdot 10^{-10}$,\\keine Werte $\neq$ 1}\\
    \lstinline[basicstyle=\ttfamily\color{black}]|fminunc| & 925 & 212.60s & $10^{-8}$ & \makecell[r]{Zielfunktionswert: $1.9\cdot 10^{-10}$,\\keine Werte $\neq$ 1}\\
    \hline
  \end{tabular}
  \caption{Unterschiede zwischen beiden Verfahren bei der Berechnung der N-dimensionalen Rosenbrock-Funktion bei hohen Dimensionen}
  \end{adjustwidth}
\end{figure}

Möglichkeiten um ein höheres $N$ zu erreichen:
\begin{itemize}
  \item Nach den Regeln der Analysis lässt sich eine Summe aufteilen in zwei Summen:
  $$\sum_{i=1}^{N-1}(1 - x_i)^2 + 100\cdot(x_{i+1}-x_i^2)^2$$
  $$=$$
  $$\sum_{i=1}^{a}(1 - x_i)^2 + 100\cdot(x_{i+1}-x_i^2)^2 + \sum_{i=a+1}^{N-1}(1 - x_i)^2 + 100\cdot(x_{i+1}-x_i^2)^2$$
  Die Berechnung des Minimums dieser zwei Summen kann auf z.B. zwei Threads aufgeteilt und am Ende wieder zusammengefügt werden.
  Bei ungeradem $N$ muss man sich entscheiden wie die Summe aufgeteilt wird, ein Thread bearbeitet dann eine Dimension mehr als der andere.
  Bei besonders großem $N$ können auch diese beiden Summen wiederum aufgeteilt und somit auf noch mehr Threads verteilt werden.
  \item Verwenden von sparse-Matritzen und Vektoren durch die sich die Rechenzeit unter Umständen reduzieren kann. Sparse-Datenstrukturen
  verwenden eine spezielle Repräsentation der Werte in denen Einträge mit $0$ effizienter gespeichert werden. Aufgrundessen beschleunigt
  sich die Berechnung von Matrix-Vektor-Produkten (die beim BFGS-Verfahren sehr oft verwendet werden)
  \item Gegebenfalls genauere Untersuchungen über Kondition und Stabilität der Operationen bzw. wie diese verbessert werden können.
  Durch Auslöschung in der Update-Formel könnte es unter Umständen zu fehlerhaften Richtungsvektoren kommen die sich bei besonders
  großen Problemen potenzieren und somit die Konvergenz verlangsamen.
\end{itemize}

\subsubsection{Aufgabe 5}

Die gegebene symmetrische Rang-1 Formel erhält man durch eine Rang-1 Modifikation

$$A^{k + 1} = A^k + c\cdot u\cdot v^T$$

mit $c = \frac{1}{u^Ts}$, $u = y - A^ks$ und $v = c\cdot u$.

Diese kann man nun in die Sherman-Morrison-Woodbury-Formel einsetzen und erhält somit den Ansatz:

$$ A^{-1} - \frac{ A^{-1}(y-As)\left(\frac{ y-As }{ (y-As)^Ts } \right)^TA^{-1} }{1 + \left(\frac{ y-As }{ (y-As)^Ts }\right)^TA^{-1}(y-As)}$$

Wenn man das T in den Bruch im Nenner und Zähler einfließen lässt, erhält man diesen Doppelbruch:

$$ A^{-1} - \frac{ \frac{A^{-1}(y-As)(y-As)^TA^{-1}}{\left( (y-As)^Ts\right)^T } }{1 + \frac{(y-As)^TA^{-1}(y-As)}{\left( (y-As)^Ts\right)^T}}$$

Nun den Zähler vom Zähler ausmultipliziert:

$$ A^{-1} - \frac{ \frac{ (A^{-1}y - A^{-1}As)(y^T-(As)^T)A^{-1} }{\left( (y-As)^Ts\right)^T } }{1 + \frac{(y-As)^TA^{-1}(y-As)}{\left( (y-As)^Ts\right)^T}}$$

$$ A^{-1} - \frac{ \frac{ (A^{-1}y - s)(y^T - s^TA)A^{-1} }{\left( (y-As)^Ts\right)^T } }{1 + \frac{(y-As)^TA^{-1}(y-As)}{\left( (y-As)^Ts\right)^T}}$$

$$ A^{-1} - \frac{ \frac{ (A^{-1}y - s)(y^TA^{-1} - s^TAA^{-1}) }{\left( (y-As)^Ts\right)^T } }{1 + \frac{(y-As)^TA^{-1}(y-As)}{\left( (y-As)^Ts\right)^T}}$$

$$ A^{-1} - \frac{ \frac{ (A^{-1}y-s)(y^TA^{-1}-s^T) }{\left( (y-As)^Ts\right)^T } }{1 + \frac{(y-As)^TA^{-1}(y-As)}{\left( (y-As)^Ts\right)^T}}$$

Ebenfalls den Zähler im Nenner ausmultiplizieren:

$$ A^{-1} - \frac{ \frac{ (A^{-1}y-s)(y^TA^{-1}-s^T) }{\left( (y-As)^Ts\right)^T } }{1 + \frac{ (y^T - (As)^T)A^{-1}(y - As) }{\left( (y-As)^Ts\right)^T}}$$

$$ A^{-1} - \frac{ \frac{ (A^{-1}y-s)(y^TA^{-1}-s^T) }{\left( (y-As)^Ts\right)^T } }{1 + \frac{ (y^T - s^TA)A^{-1}(y-As) }{\left( (y-As)^Ts\right)^T}}$$

$$ A^{-1} - \frac{ \frac{ (A^{-1}y-s)(y^TA^{-1}-s^T) }{\left( (y-As)^Ts\right)^T } }{1 + \frac{ (y^TA^{-1} - s^T)(y - As) }{\left( (y-As)^Ts\right)^T}}$$

$$ A^{-1} - \frac{ \frac{ (A^{-1}y-s)(y^TA^{-1}-s^T) }{\left( (y-As)^Ts\right)^T } }{1 + \frac{ y^TA^{-1}y - y^TA^{-1}As - s^Ty + s^TAs }{\left( (y-As)^Ts\right)^T}}$$

$$ A^{-1} - \frac{ \frac{ (A^{-1}y-s)(y^TA^{-1}-s^T) }{\left( (y-As)^Ts\right)^T } }{1 + \frac{ y^TA^{-1}y - y^Ts - s^Ty + s^TAs }{\left( (y-As)^Ts\right)^T}}$$

$$ A^{-1} - \frac{ \frac{ (A^{-1}y-s)(y^TA^{-1}-s^T) }{\left( (y-As)^Ts\right)^T } }{1 + \frac{ y^T(A^{-1}y - s) - s^T(y - As) }{\left( (y-As)^Ts\right)^T}}$$

Die $1$ im Nenner erweitern:

$$ A^{-1} - \frac{ \frac{ (A^{-1}y-s)(y^TA^{-1}-s^T) }{\left( (y-As)^Ts\right)^T } }{ \frac{\left( (y-As)^Ts\right)^T}{\left( (y-As)^Ts\right)^T} + \frac{ y^T(A^{-1}y - s) - s^T(y - As) }{\left( (y-As)^Ts\right)^T}}$$

mit dem zweiten Term verbinden:

$$ A^{-1} - \frac{ \frac{ (A^{-1}y-s)(y^TA^{-1}-s^T) }{\left( (y-As)^Ts\right)^T } }{ \frac{ \left( (y-As)^Ts\right)^T + y^T(A^{-1}y - s) - s^T(y - As) }{\left( (y-As)^Ts\right)^T}}$$

ausmultiplizieren:

$$ A^{-1} - \frac{ \frac{ (A^{-1}y-s)(y^TA^{-1}-s^T) }{\left( (y-As)^Ts\right)^T } }{ \frac{ s^T(y - As) + y^TA^{-1}y - y^Ts - s^Ty + s^TAs }{\left( (y-As)^Ts\right)^T}}$$

$$ A^{-1} - \frac{ \frac{ (A^{-1}y-s)(y^TA^{-1}-s^T) }{\left( (y-As)^Ts\right)^T } }{ \frac{ s^Ty - s^TAs + y^TA^{-1}y - y^Ts - s^Ty + s^TAs }{\left( (y-As)^Ts\right)^T}}$$

und kürzen:

$$ A^{-1} - \frac{ \frac{ (A^{-1}y-s)(y^TA^{-1}-s^T) }{\left( (y-As)^Ts\right)^T } }{ \frac{ y^TA^{-1}y - y^Ts }{\left( (y-As)^Ts\right)^T}}$$

$$ A^{-1} - \frac{ \frac{ (A^{-1}y-s)(y^TA^{-1}-s^T) }{\left( (y-As)^Ts\right)^T } }{ \frac{ y^T(A^{-1}y - s) }{\left( (y-As)^Ts\right)^T}}$$

Den Doppelbruch auflösen:

$$ A^{-1} - \frac{ (A^{-1}y-s)(y^TA^{-1}-s^T) }{\left( (y-As)^Ts\right)^T } \cdot \frac{ \left( (y-As)^Ts\right)^T }{ y^T(A^{-1}y - s) }$$

Wenn man sich die nun gegenüberstehenden Terme ansieht:

$$\left( (y-As)^Ts\right)^T$$

erkennt man, dass es sich hierbei um eine Zahl handelt (beispielhaft für ein $2\times 2$-System):

$$\left( \left(\begin{bmatrix}1\\1\end{bmatrix} - \begin{bmatrix}2 & 3\\3 & -1\end{bmatrix}\cdot \begin{bmatrix}3\\2\end{bmatrix} \right)^T\cdot \begin{bmatrix}3\\2\end{bmatrix} \right)^T$$

$$\left( \left(\begin{bmatrix}1\\1\end{bmatrix} - \begin{bmatrix}12\\7\end{bmatrix} \right)^T \cdot \begin{bmatrix}3\\2\end{bmatrix} \right)^T$$

$$\left( \left(\begin{bmatrix}-11\\-6\end{bmatrix} \right)^T \cdot \begin{bmatrix}3\\2\end{bmatrix} \right)^T$$

$$\left( \begin{bmatrix}-11 & -6\end{bmatrix} \cdot \begin{bmatrix}3\\2\end{bmatrix} \right)^T$$

$$\left( -45 \right)^T = -45$$

D.h. man darf den Doppelbruch kürzen, dann erhält man:

$$ A^{-1} - \frac{ (A^{-1}y - s)(y^TA^{-1} - s^T) }{ y^T(A^{-1}y - s) } $$

Um den Ausdruck noch schöner zu machen, kann man jeweils ein Minus aus den zwei Termen im Zähler herausziehen:

$$ A^{-1} - \frac{ (-A^{-1}y + s)(-y^TA^{-1} + s^T) }{ y^T(A^{-1}y - s) } $$

und Summanden vertauschen:

$$ A^{-1} - \frac{ (s - A^{-1}y )(s^T - y^TA^{-1}) }{ y^T(A^{-1}y - s) } $$

Aus dem rechten Term kann man aufgrund der Symmetrie das Transponieren herausziehen:

$$ A^{-1} - \frac{ (s - A^{-1}y )(s - A^{-1}y)^T }{ y^T(A^{-1}y - s) } $$

Weiterhin kann man aus dem Nenner ebenfalls ein Minus entwenden und die Summanden vertauschen:

$$ A^{-1} + \frac{ (s - A^{-1}y )(s - A^{-1}y)^T }{ y^T(s - A^{-1}y) } $$

Da es sich beim Nenner ebenfalls um eine Zahl handelt (beispielhaft für ein $2\times 2$-System):

$$\begin{bmatrix}1 & 2\end{bmatrix}\left(\begin{bmatrix}3\\1\end{bmatrix} - \begin{bmatrix}1 & -2\\-2 & 3\end{bmatrix}\cdot\begin{bmatrix}1\\2\end{bmatrix}\right)$$

kann man ihn auch so schreiben:

$$ A^{-1} + \frac{ (s - A^{-1}y )(s - A^{-1}y)^T }{ (s - A^{-1}y)^Ty } $$

Damit erhält man nun die Update-Formel für das Inverse-Verfahren:

$$B^{(k+1)} = B^{k} + \frac{(s^k - B^ky^k)(s^k - B^ky^k)^T}{(s^k-B^ky^k)^Ty^k}$$

\subsubsection{Aufgabe 6}

Siehe \lstinline[basicstyle=\ttfamily\color{black}]|GaussNewton.m|.

\subsubsection{Aufgabe 7}

Die erste Funktion

$$f(t, x_1, x_2) = x_1\cdot e^{x_2\cdot t}$$

mit partiellen Ableitungen:

$$\frac{df}{dx_1} = e^{x_2\cdot t} , \frac{df}{dx_2} = t\cdot x_1 \cdot e^{x_2\cdot t} $$

hat mit dem gegebenen Datensatz folgenden Residuen-Vektor:

\def\arraystretch{1.25}
$$r = \begin{bmatrix} f(0, x_1, x_2) - 2 \\ f(1, x_1, x_2) - 0.7 \\ f(2, x_1, x_2) - 0.3 \\ f(3, x_1, x_2) - 0.1\end{bmatrix}$$

und diese Jacobi-Matrix:

$$ J = \begin{bmatrix}
  \frac{df}{dx_1}(0, x_1, x_2) & \frac{df}{dx_2}(0, x_1, x_2)\\
  \frac{df}{dx_1}(1, x_1, x_2) & \frac{df}{dx_2}(1, x_1, x_2)\\
  \frac{df}{dx_1}(2, x_1, x_2) & \frac{df}{dx_2}(2, x_1, x_2)\\
  \frac{df}{dx_1}(3, x_1, x_2) & \frac{df}{dx_2}(3, x_1, x_2)\\
\end{bmatrix}$$

\begin{figure}[H]
  \centering
  \def\arraystretch{1.25}
  \begin{tabular}{l|c|r}
    \hline
    \textbf{Schritt} & \textbf{x} & \textbf{$\sum_{i=1}^M (r_i)^2$}\\
    \hline
    1 & $[0.50, 1.00]^T$ & 113.07\\
    2 & $[0.39, 0.74]^T$ & 16.64\\
    3 & $[0.69, 0.14]^T$ & 2.99\\
    4 & $[1.54, -0.66]^T$ & 0.24\\
    5 & $[1.98, -0.99]^T$ & $2.5\cdot 10^{-3}$\\
    $\vdots$ & $\vdots$ & $\vdots$\\
    10 & $[2.00, -1.0]^T$ & $2.0\cdot 10^{-3}$\\
    \hline
  \end{tabular}
  \caption{Verlauf der aufsummierten quadratischen Residuen mit dem gegebenen Datensatz und
  \lstinline[basicstyle=\ttfamily\color{black}]|GaussNewton.m| bei Abbruchbedingung $||\nabla f|| \leq 10^{-8}$ }
\end{figure}

Für $f$ erhält man somit die Werte $x_1 = 1.9950$ und $x_2 = -1.0095$ nach $10$ Iterationen.\par

Weiterhin gilt für die zweite Funktion

$$g(t, x_1, x_2, x_3) = x_1\cdot e^{-(x_2^2 + x_3^2)\cdot t}\cdot \frac{\text{sinh}(x_3^2\cdot t)}{x_3^2}$$

mit den partiellen Ableitungen

$$\frac{dg}{dx_1} = e^{ -(x_2^2 + x_3^2)\cdot t } \cdot \frac{\text{sinh}( x_3^2 \cdot t) }{ x_3^2 } $$

$$\frac{dg}{dx_2} = - 2t \cdot x_2 x_1 \cdot e^{ - (x_2^2 + x_3^2)\cdot t } \cdot \frac{\text{sinh}( x_3^2 \cdot t )}{ x_3^2} $$

$$\frac{dg}{dx_3} = \frac{2 \cdot x_1 \cdot e^{ -(x_2^2 + x_3^2)\cdot t} \cdot \left( t \cdot x_3^2 \cdot \text{cosh}(x_3^2\cdot t) - (x_3^2\cdot t + 1) \cdot \text{sinh}(x_3^2 \cdot t) \right) }{x_3^2} $$

Für die zweite Funktion $g(t, x_1, x_2, x_3) = x_1 \cdot e^{ -(x_2^2 + x_3^2)\cdot t }\cdot \frac{sinh(x_3^2\cdot t)}{x_3^2}$
erhält man mit dem gegebenen Datensatz und den Startwerten:
\begin{itemize}
  \item $x_0 = [10, 0.05, 0.1]^T$
  \item $x_0 = [7, 0.125, 0.25]^T$
  \item $x_0 = [3, 0.1, 0.05]^T$
\end{itemize}
die Werte
\begin{itemize}
  \item $x_1 = 3.5355$, $x_2 = 0.0546$, $x_3 = 0.1539$
\end{itemize}
nach $117$, $247$ bzw. $609$ Iterationen. Abbruchkriterium war ||$J(x)^T\cdot r(x)$|| $ \leq 10^{-8}$. Die Wolfe-Powell
Schrittweitensteuerung hat bei dieser Funktion nicht zum Erfolg geführt da nach etwa 10 Durchläufen eine sehr kleine
Schrittweite (im Bereich $\alpha = 10^{-8}$) angenommen wurde und das Verfahren daher nicht konvergiert ist. Wählt
man dagegen händisch eine kleine Schrittweite (z.B. $\alpha = 0.1$ oder je nach Startwert $\alpha = 0.05$) konvergiert das
Verfahren wieder.\par
Allgemein reagiert die Funktion $g$ sehr empfindlich auf kleine Änderungen in den Startwerten. Das liegt vermutlich an den
stark unterschiedlichen Werten der einzelnen Faktoren ($x_1\cdot e^-{ (x_2^2 + x_3^2)\cdot t}$ ist sehr klein während
$\frac{sinh(x_3^2\cdot t)}{x_3^2}$ sehr groß wird) aufgrundessen es zu numerischer Instabilität kommt (z.B. zeigt Matlab
dann \lstinline[basicstyle=\ttfamily\color{black}]|NaN|).

% TODO: Residuum einzeichnen

\subsubsection{Aufgabe 8}

\begin{figure}[H]
  \centering
  \begin{tikzpicture}
    \newcommand*{\from}{-0.5}
    \newcommand*{\too}{3.5}
    \newcommand*{\scaleFactor}{1.5}
    \tikzstyle{interval border}=[thin, red];

    \draw[-{Latex}] (\from,0) -- (\too*\scaleFactor,0) node[right] {$t$};
    \draw[-{Latex}] (0,\from) -- (0,\too*\scaleFactor) node[above] {\rotatebox{0}{$f(t, 1.995, -1.0095)$}}; 
    \draw[scale=\scaleFactor, thick, black, domain=\from:\too, smooth, variable=\x] plot ({\x},{1.995 * exp(-1.0095 * \x)});

    \draw (0, 0) node[xshift=-0.21cm, yshift=-0.25cm, font=\small] {$0$};

    \foreach \x in {1, 2, 3} {
      \draw (\x*\scaleFactor, 0) node[yshift=-0.25cm, font=\small] {$\x$};
      \draw (0,\x*\scaleFactor) node[xshift=-0.25cm, font=\small] {$\x$};
    }

    \foreach \x / \y / \i in {0/2.0/1, 1/0.7/2, 2/0.3/3, 3/0.1/4} {
      \draw (\x*\scaleFactor, \y*\scaleFactor) node[interval border] {x};
    }
  \end{tikzpicture}
  \caption{Modellfunktion und Datensatz für $f(t, x_1, x_2) = x_1\cdot e^{x_2\cdot t}$}
\end{figure}

\begin{figure}[H]
  \centering
  \begin{tikzpicture}
    \newcommand*{\from}{0}
    \newcommand*{\too}{190}
    \newcommand*{\scaleFactor}{0.03075}
    \tikzstyle{interval border}=[thin, red];
    \draw[-{Latex}] (\from,0) -- (\too*\scaleFactor,0) node[right] {$t$};
    \draw[-{Latex}] (0,\from) -- (0,\too*\scaleFactor) node[above] {\rotatebox{0}{$g(t, 3.5355, 0.0546, 0.1539)$}};

    \draw (0, 0) node[xshift=-0.21cm, yshift=-0.25cm, font=\small] {$0$};
    \foreach \x in {40, 80, 120, 160} {
      \draw (\x*\scaleFactor, 0) node[yshift=-0.25cm, font=\small] {$\x$};
      \draw (0,\x*\scaleFactor) node[xshift=-0.425cm, font=\small] {$\x$};
    }

    \draw[scale=\scaleFactor, thick, black, domain=\from:\too, smooth, variable=\x] plot (
      {\x},{ 3.5355 * exp( -(0.0546^2 + 0.1539^2) * \x ) * ( sinh(0.1539^2 * \x) / (0.1539^2) ) }
    );

    \foreach \x / \y / \i in {
      6/24.19/1, 12/35.34/2, 18/43.43/3, 24/42.63/4, 30/49.92/5, 36/51.53/6, 42/57.39/7, 48/59.56/8, 54/55.60/9, 60/51.91/10,
      66/58.27/11, 72/62.99/12, 78/52.99/13, 84/53.83/14, 90/59.37/15, 96/62.35/16, 102/61.84/17, 108/61.62/18, 114/49.64/19,
      120/57.81/20, 126/54.79/21, 132/50.38/22, 138/43.85/23, 144/45.16/24, 150/46.72/25, 156/40.68/26, 162/35.14/27, 168/45.47/28,
      174/42.40/29, 180/55.21/30
    } {
      \draw (\x*\scaleFactor, \y*\scaleFactor) node[interval border] {x};
    }

  \end{tikzpicture}
  \caption{Modellfunktion und Datensatz für $g(t, x_1, x_2, x_3) =$\\$x_1 \cdot e^{ -(x_2^2 + x_3^2)\cdot t }\cdot \frac{sinh(x_3^2\cdot t)}{x_3^2}$}
\end{figure}

\subsubsection{Aufgabe 9}
Bei einem Least-Squares-Problem wird der Abstand von einer Funktion $f$ zu den gegebenen Datenpunkten $(t,y)$ minimiert,
die Zielfunktion (nach Foliensatz) ist daher:

$$f_{LeastSquares}(x) = \sum_{i=1}^m (f(t_i, x_1, x_2, ..., x_n) - y_i)^2$$

Es werden also alle Residuen:

$$r(x) = \begin{bmatrix}f(t_1, x_1, ..., x_n) - y_1\\f(t_2, x_1, ..., x_n) - y_2\\ \vdots \end{bmatrix}$$

quadriert und aufsummiert. $f_{LeastSquares}(x)$ ist somit der erste Parameter, den\\
\lstinline[basicstyle=\ttfamily\color{black}]|InverseBFGS| erhält.\par
Weiterhin ist die Jacobi-Matrix definiert als:

$$J = \begin{bmatrix}\frac{df}{x_1}(t_1, x_1, ..., x_n) && \frac{df}{x_2}(t_1, x_1, ..., x_n) && \ldots\\
            \frac{df}{x_1}(t_2, x_1, ..., x_n) && \frac{df}{x_2}(t_2, x_1, ..., x_n) && \ldots\\
            \vdots && \vdots && \vdots\end{bmatrix}$$

Nach Foliensatz ist der Gradient definiert als: $\nabla f(x) = 2\cdot J(x)^T\cdot r(x)$. Dies ist der zweite Parameter, den
das BFGS-Verfahren erhält, zusammen mit einem Startwert.\par
Für die erste Funktion $f(t, x_1, x_2) = x_1\cdot e^{x_2\cdot t}$ liefert das BFGS-Verfahren den korrekten Wert. Für die
zweite Funktion liefert es jedoch z.B.\\
$[9.8962, 11.4152, 1.5202]^T$ da beim ersten Durchlauf der Wert des negativen Gradienten
verwendet wird (da $B = I$) und dadurch die Norm des Gradienten auf 0 sinkt (Abbruchbedingung).

\end{document}